#!/usr/bin/env python3
"""
HMI-ROBOT.py - Robot de Surveillance avec Raspberry Pi 4
Version modifi√©e avec support cam√©ra Raspberry Pi CSI
"""

import tkinter as tk
from tkinter import ttk, messagebox, filedialog
import cv2
import numpy as np
from PIL import Image, ImageTk
import csv
from datetime import datetime
import os
import json
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
import threading
import time
import sys

# --- D√©tection automatique GPIO ---
try:
    import RPi.GPIO as GPIO
    GPIO_AVAILABLE = True
except ImportError:
    GPIO_AVAILABLE = False
    print("‚ö†Ô∏è  RPi.GPIO non disponible - mode simulation activ√©")

try:
    import serial
    SERIAL_AVAILABLE = True
except ImportError:
    serial = None
    SERIAL_AVAILABLE = False
    print("‚ö†Ô∏è  pyserial non disponible - commandes moteur d√©sactiv√©es")

class MotorBridge:
    """Simple serial bridge to the Arduino motor controller."""

    def __init__(self, port, baudrate=115200, timeout=0.2):
        self.port = port
        self.baudrate = baudrate
        self.timeout = timeout
        self.serial = None
        try:
            self.serial = serial.Serial(port=port, baudrate=baudrate, timeout=timeout)
            print(f"‚úÖ Pont moteur connect√© sur {port}")
        except Exception as exc:
            print(f"‚ùå Erreur connexion pont moteur: {exc}")

    def send_command(self, payload):
        if not self.serial or not self.serial.is_open:
            return False
        try:
            data = json.dumps(payload).encode("utf-8") + b"\n"
            self.serial.write(data)
            return True
        except Exception as exc:
            print(f"[MotorBridge] √âchec envoi: {exc}")
            return False

    def close(self):
        try:
            if self.serial and self.serial.is_open:
                self.serial.close()
                print("‚úÖ Pont moteur ferm√©")
        except Exception:
            pass

class VisionHMI:
    def __init__(self, root):
        self.root = root
        self.root.title("ü§ñ Robot de Surveillance - Raspberry Pi 4")
        self.root.geometry("1280x720")
        self.root.minsize(1024, 600)
        self.root.configure(bg="#2c3e50")
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        
        # Variables de cam√©ra
        self.cap = None
        self.picam2 = None
        self.use_static_image = False
        self.static_image = None
        self.camera_type = None  # "picamera2", "usb", ou "static"
        
        # Initialisation de la cam√©ra (M√âTHODE MODIFI√âE POUR RASPBERRY PI)
        self.init_camera()
        
        # Modes
        self.mode = tk.StringVar(value="Mode R√©glage")
        self.mode.trace("w", self.update_mode)
        
        # ROI management
        self.rois = []
        self.selected_roi = None
        self.drawing = False
        self.resizing = False
        self.moving = False
        self.rotating = False
        self.drawing_mask = False
        self.ix, self.iy = -1, -1
        self.roi_id = 0
        self.hovered_roi = None
        self.snap_to_grid = tk.BooleanVar(value=False)
        self.roi_shape = tk.StringVar(value="rectangle")
        
        # Surveillance parameters
        self.params = {
            "gpio_trigger_pin": tk.IntVar(value=-1),
            "yolo_confidence": tk.DoubleVar(value=0.5),
            "face_scale_factor": tk.DoubleVar(value=1.1),
            "face_min_neighbors": tk.IntVar(value=5),
        }
        
        # Surveillance features only
        self.surveillance_features = {
            "YOLO Person Detection": tk.BooleanVar(value=True),
            "Face Detection": tk.BooleanVar(value=False),
            "Motion Detection": tk.BooleanVar(value=False),
        }
        
        # Surveillance cycle
        self.cycle_state = "Idle"
        self.cycle_results = {}
        
        # GPIO simulation
        self.gpio_trigger_active = False
        self.gpio_thread = None
        
        # Logging
        self.log_file = "robot_surveillance_log.csv"
        self.init_log()
        
        # YOLO integration
        self.yolo_enabled = tk.BooleanVar(value=False)
        self.yolo_model = None
        
        # Face detection
        self.face_enabled = tk.BooleanVar(value=False)
        self.face_cascade = None
        
        # Surveillance features
        self.surveillance_mode = tk.BooleanVar(value=False)
        self.motion_detection = tk.BooleanVar(value=False)
        self.alert_threshold = tk.DoubleVar(value=0.5)
        self.last_detection_time = None
        self.detection_count = 0
        self.current_detections = 0
        self.behavior_flags = {
            "detect_all_objects": tk.BooleanVar(value=True),
            "smart_obstacle_mode": tk.BooleanVar(value=True),
        }
        self.detect_all_objects = self.behavior_flags["detect_all_objects"]
        self.smart_obstacle_mode = self.behavior_flags["smart_obstacle_mode"]
        self.current_detection_summary = {"human": 0, "obstacle": 0}
        self.human_class_ids = {0}  # YOLO class 0 = person
        
        # Configuration moteur
        self.serial_port = "/dev/ttyACM0"  # Port typique pour Arduino sur Raspberry Pi
        self.motor_bridge = None
        self.last_turn_direction = "left"
        self.buzzer_enabled = tk.BooleanVar(value=True)
        self.human_avoidance_stop_duration = 3.0
        self.human_avoidance_turn_duration = 1200
        self.is_avoiding_human = False
        
        # --- Mode simulation GPIO ---
        self.gpio_simulation = not GPIO_AVAILABLE
        
        # Setup GPIO r√©el si disponible
        if GPIO_AVAILABLE:
            self.setup_real_gpio()
        
        # Initialisation du pont moteur
        self.motor_bridge = self.init_motor_bridge()
        
        # Setup GUI
        self.setup_gui()
        self.load_settings()
        
        # D√©marrer le flux vid√©o
        self.update_video()
        
        # D√©marrer simulation GPIO (si pin configur√©)
        self.start_gpio_simulation()
        
        self.last_live_blob_results = None
        print("‚úÖ Interface Robot de Surveillance initialis√©e")

    # ==================== M√âTHODE INIT_CAMERA MODIFI√âE POUR RASPBERRY PI ====================
    def init_camera(self):
        """Initialise soit la cam√©ra CSI du Raspberry Pi, soit une webcam USB, soit une image statique."""
        self.cap = None
        self.picam2 = None
        self.use_static_image = False
        self.camera_type = None
        
        print("üîç Recherche des cam√©ras disponibles...")
        
        # OPTION 1: Essayer la cam√©ra CSI du Raspberry Pi avec picamera2
        try:
            from picamera2 import Picamera2
            print("üì∑ Tentative d'initialisation de la cam√©ra Raspberry Pi (CSI)...")
            self.picam2 = Picamera2()
            
            # Configuration pour l'aper√ßu
            preview_config = self.picam2.create_preview_configuration(
                main={"size": (640, 480)},
                controls={"FrameRate": 30}
            )
            self.picam2.configure(preview_config)
            self.picam2.start()
            
            # Test rapide de capture
            test_frame = self.picam2.capture_array()
            if test_frame is not None and test_frame.size > 0:
                self.camera_type = "picamera2"
                print("‚úÖ Cam√©ra Raspberry Pi (CSI) activ√©e avec succ√®s!")
                self.show_toast("‚úÖ Cam√©ra Raspberry Pi activ√©e", duration=3000)
                return
            else:
                self.picam2.stop()
                self.picam2.close()
                self.picam2 = None
                print("‚ö†Ô∏è  Capture test √©chou√©e avec picamera2")
                
        except ImportError:
            print("‚ùå picamera2 non install√©. Installer avec: sudo apt install python3-picamera2")
        except Exception as e:
            print(f"‚ùå Erreur cam√©ra Raspberry Pi: {e}")
            if hasattr(self, 'picam2') and self.picam2:
                try:
                    self.picam2.close()
                except:
                    pass
                self.picam2 = None
        
        # OPTION 2: Essayer une webcam USB
        print("üîå Essai avec webcam USB...")
        for camera_index in range(4):  # Essayer /dev/video0 √† /dev/video3
            try:
                cap = cv2.VideoCapture(camera_index)
                if cap.isOpened():
                    # Tester la capture
                    ret, test_frame = cap.read()
                    if ret and test_frame is not None:
                        # Configurer la r√©solution
                        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                        cap.set(cv2.CAP_PROP_FPS, 30)
                        self.cap = cap
                        self.camera_type = f"usb_{camera_index}"
                        print(f"‚úÖ Webcam USB d√©tect√©e sur /dev/video{camera_index}")
                        self.show_toast(f"‚úÖ Webcam USB d√©tect√©e (index {camera_index})", duration=3000)
                        return
                    else:
                        cap.release()
                else:
                    cap.release()
            except Exception as e:
                print(f"‚ùå Erreur webcam index {camera_index}: {e}")
                continue
        
        # OPTION 3: Fallback - Image statique
        print("‚ö†Ô∏è  Aucune cam√©ra trouv√©e. Utilisation du mode image statique.")
        self.use_static_image = True
        
        # Essayer de charger une image d'exemple
        sample_images = ["sample_image.jpg", "test_image.png", "/usr/share/raspberrypi-artwork/raspberry-pi-logo.png"]
        for img_path in sample_images:
            if os.path.exists(img_path):
                self.static_image = cv2.imread(img_path)
                if self.static_image is not None:
                    print(f"‚úÖ Image statique charg√©e: {img_path}")
                    break
        
        # Si aucune image trouv√©e, cr√©er une image noire avec message
        if self.static_image is None:
            self.static_image = np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.putText(self.static_image, "ü§ñ ROBOT DE SURVEILLANCE", (50, 150), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            cv2.putText(self.static_image, "Aucune camera detectee", (100, 200), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(self.static_image, "Mode simulation active", (120, 250), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            print("‚úÖ Image de simulation cr√©√©e")
        
        self.camera_type = "static"
        self.show_toast("‚ö†Ô∏è  Mode image statique (pas de cam√©ra)", duration=5000)

    def ensure_yolo_loaded(self):
        try:
            if self.yolo_model is None:
                print("üîÑ Chargement du mod√®le YOLOv8n...")
                from ultralytics import YOLO
                self.yolo_model = YOLO("yolov8n.pt")  # Mod√®le nano pour Raspberry Pi
                # Configuration optimis√©e pour Raspberry Pi
                self.yolo_model.overrides['imgsz'] = 320
                self.yolo_model.overrides['device'] = 'cpu'
                self.yolo_model.overrides['half'] = False
                self.yolo_model.overrides['verbose'] = False
                print("‚úÖ Mod√®le YOLOv8n charg√© avec succ√®s")
        except Exception as e:
            print(f"‚ùå Erreur chargement YOLO: {e}")
            self.yolo_enabled.set(False)

    def ensure_haar_loaded(self):
        try:
            if self.face_cascade is None:
                print("üîÑ Chargement du classifieur Haar...")
                haar_path = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
                self.face_cascade = cv2.CascadeClassifier(haar_path)
                if self.face_cascade.empty():
                    raise Exception("Fichier Haar non trouv√©")
                print("‚úÖ Classifieur Haar charg√© avec succ√®s")
        except Exception as e:
            print(f"‚ùå Erreur chargement Haar: {e}")
            self.face_enabled.set(False)

    def setup_real_gpio(self):
        """Setup GPIO r√©el pour Raspberry Pi"""
        try:
            GPIO.setmode(GPIO.BCM)
            GPIO.setwarnings(False)
            # Configuration des pins pour robot
            self.led_pins = {
                'ok': 18,    # LED verte
                'ng': 19,    # LED rouge
                'alert': 20  # LED bleue
            }
            # Buzzer
            self.buzzer_pin = 21
            
            # Configuration des pins en sortie
            for pin in self.led_pins.values():
                GPIO.setup(pin, GPIO.OUT)
                GPIO.output(pin, GPIO.LOW)
            GPIO.setup(self.buzzer_pin, GPIO.OUT)
            GPIO.output(self.buzzer_pin, GPIO.LOW)
            print("‚úÖ GPIO Raspberry Pi configur√©")
            self.show_toast("‚úÖ GPIO r√©el configur√©", duration=2000)
        except Exception as e:
            print(f"‚ùå Erreur GPIO: {e}")
            self.show_toast(f"‚ùå Erreur GPIO: {e}")

    def init_motor_bridge(self):
        """Initialise la liaison s√©rie avec le contr√¥leur moteur."""
        if not SERIAL_AVAILABLE:
            print("‚ö†Ô∏è  pyserial indisponible - commandes moteur d√©sactiv√©es")
            self.show_toast("‚ö†Ô∏è  Commandes moteur d√©sactiv√©es (pyserial manquant)", duration=3000)
            return None
        
        ports_to_try = ["/dev/ttyACM0", "/dev/ttyACM1", "/dev/ttyUSB0", "/dev/ttyUSB1"]
        
        for port in ports_to_try:
            try:
                if os.path.exists(port):
                    print(f"üîå Tentative de connexion sur {port}...")
                    bridge = MotorBridge(port, baudrate=115200, timeout=0.2)
                    if bridge.serial and bridge.serial.is_open:
                        return bridge
            except Exception as e:
                print(f"‚ùå √âchec connexion sur {port}: {e}")
                continue
        
        print("‚ö†Ô∏è  Aucun contr√¥leur moteur d√©tect√©")
        self.show_toast("‚ö†Ô∏è  Aucun contr√¥leur moteur d√©tect√©", duration=3000)
        return None

    # ==================== M√âTHODE UPDATE_VIDEO MODIFI√âE POUR RASPBERRY PI ====================
    def update_video(self):
        try:
            # === CAPTURE DE LA FRAME ===
            if self.use_static_image:
                frame = self.static_image.copy()
                
            elif self.camera_type == "picamera2" and self.picam2:
                # Capture depuis la cam√©ra Raspberry Pi
                try:
                    frame = self.picam2.capture_array()
                    if frame is not None:
                        # Convertir RGB en BGR pour OpenCV
                        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    else:
                        print("‚ö†Ô∏è  Capture picamera2 retourn√©e None")
                        self.root.after(40, self.update_video)
                        return
                except Exception as e:
                    print(f"‚ùå Erreur capture picamera2: {e}")
                    self.root.after(40, self.update_video)
                    return
                    
            elif self.cap and self.camera_type and self.camera_type.startswith("usb"):
                # Capture depuis webcam USB
                ret, frame = self.cap.read()
                if not ret:
                    print("‚ö†Ô∏è  √âchec capture USB, tentative de r√©ouverture...")
                    # Tenter de r√©initialiser
                    self.cap.release()
                    time.sleep(0.1)
                    camera_index = int(self.camera_type.split("_")[1])
                    self.cap = cv2.VideoCapture(camera_index)
                    if self.cap.isOpened():
                        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                        ret, frame = self.cap.read()
                    
                    if not ret:
                        self.root.after(100, self.update_video)
                        return
            else:
                # Aucune source valide
                self.root.after(100, self.update_video)
                return
            
            # === TRAITEMENT DE LA FRAME ===
            
            # D√©tection YOLO
            if self.yolo_enabled.get():
                self.ensure_yolo_loaded()
                try:
                    classes_filter = None if self.detect_all_objects.get() else [0]
                    results = self.yolo_model.predict(
                        frame,
                        classes=classes_filter,
                        conf=self.params["yolo_confidence"].get(),
                        verbose=False,
                        save=False,
                        save_txt=False,
                        save_conf=False,
                    )
                    
                    self.current_detections = 0
                    self.current_detection_summary = {"human": 0, "obstacle": 0}
                    
                    for r in results:
                        if getattr(r, 'boxes', None) is None:
                            continue
                        for b in r.boxes:
                            x1, y1, x2, y2 = map(int, b.xyxy[0])
                            conf = float(b.conf[0]) if getattr(b, 'conf', None) is not None else 0.0
                            cls_id = int(b.cls[0]) if getattr(b, 'cls', None) is not None else None
                            
                            label = "unknown"
                            if self.yolo_model and hasattr(self.yolo_model, "names") and cls_id is not None:
                                label = self.yolo_model.names.get(cls_id, str(cls_id))
                            elif cls_id is not None:
                                label = str(cls_id)
                            
                            is_human = cls_id in self.human_class_ids if cls_id is not None else False
                            category = "human" if is_human else "obstacle"
                            color = (0, 255, 0) if is_human else (0, 165, 255)
                            self.current_detection_summary[category] += 1
                            
                            # Dessiner la bo√Æte
                            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                            cv2.putText(
                                frame,
                                f"{label} {conf:.2f}",
                                (x1, y1 - 6),
                                cv2.FONT_HERSHEY_SIMPLEX,
                                0.5,
                                color,
                                1,
                            )
                            
                            self.current_detections += 1
                            
                            # Surveillance mode - alerte
                            if is_human and self.surveillance_mode.get() and conf >= self.alert_threshold.get():
                                self.handle_surveillance_alert(conf)
                            elif not is_human:
                                self.handle_obstacle_detection(label, conf)
                    
                    # Mettre √† jour l'affichage des compteurs
                    if hasattr(self, 'detection_count_label'):
                        human_count = self.current_detection_summary.get("human", 0)
                        obstacle_count = self.current_detection_summary.get("obstacle", 0)
                        summary_text = f"D√©tections actuelles: Humains={human_count} | Obstacles={obstacle_count} | Alertes totales={self.detection_count}"
                        self.detection_count_label.config(text=summary_text)
                        
                except Exception as yerr:
                    print(f"‚ùå Erreur YOLO: {yerr}")
                    self.yolo_enabled.set(False)
            
            # D√©tection de visages (Haar)
            if self.face_enabled.get():
                self.ensure_haar_loaded()
                try:
                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    faces = self.face_cascade.detectMultiScale(
                        gray,
                        scaleFactor=self.params["face_scale_factor"].get(),
                        minNeighbors=self.params["face_min_neighbors"].get(),
                        minSize=(60, 60)
                    )
                    for (x, y, w, h) in faces:
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
                        cv2.putText(frame, "Visage", (x, y - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
                except Exception as herr:
                    print(f"‚ùå Erreur d√©tection visage: {herr}")
                    self.face_enabled.set(False)
            
            # === AFFICHAGE DE LA FRAME ===
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame_rgb)
            img = img.resize((640, 480), Image.Resampling.LANCZOS)
            self.photo = ImageTk.PhotoImage(image=img)
            self.canvas.create_image(0, 0, anchor=tk.NW, image=self.photo)
            
            # === MISE √Ä JOUR DES INFORMATIONS ===
            fps_text = ""
            if hasattr(self, 'last_frame_time'):
                current_time = time.time()
                fps = 1.0 / (current_time - self.last_frame_time)
                fps_text = f" | FPS: {fps:.1f}"
                self.last_frame_time = current_time
            else:
                self.last_frame_time = time.time()
            
            camera_info = f"Cam√©ra: {self.camera_type if self.camera_type else 'Non d√©tect√©e'}"
            self.status_var.set(f"Pr√™t | {camera_info}{fps_text}")
            
            # Planifier la prochaine mise √† jour
            self.root.after(40, self.update_video)  # ~25 FPS
            
        except Exception as e:
            print(f"‚ùå Erreur update_video: {e}")
            self.root.after(100, self.update_video)

    # ==================== AUTRES M√âTHODES (inchang√©es mais incluses pour compl√©tude) ====================

    def handle_surveillance_alert(self, confidence):
        """G√®re les alertes de surveillance"""
        current_time = time.time()
        
        # √âviter les alertes r√©p√©titives (cooldown 5s)
        if self.last_detection_time and (current_time - self.last_detection_time) < 5:
            return
        
        # √âviter multiples d√©clenchements
        if self.is_avoiding_human:
            return
            
        self.last_detection_time = current_time
        self.detection_count += 1
        self.is_avoiding_human = True
        
        # Log
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        alert_msg = f"üö® ALERTE #{self.detection_count} - Personne d√©tect√©e (confiance: {confidence:.2f})"
        
        try:
            with open(self.log_file, "a", newline="") as f:
                writer = csv.writer(f)
                writer.writerow([timestamp, "SURVEILLANCE", "D√©tection Personne", "ALERTE", f"Confiance: {confidence:.2f}"])
        except Exception as e:
            print(f"‚ùå Erreur log: {e}")
        
        # Alerte utilisateur
        self.show_toast(alert_msg, duration=5000)
        
        # Contr√¥le LED
        if GPIO_AVAILABLE and hasattr(self, 'led_pins'):
            try:
                GPIO.output(self.led_pins['alert'], GPIO.HIGH)
                self.root.after(2000, lambda: GPIO.output(self.led_pins['alert'], GPIO.LOW))
            except Exception as e:
                print(f"‚ùå Erreur LED: {e}")
        
        # Alarme sonore
        self.play_buzzer_pattern("human")
        
        # S√©quence d'√©vitement
        self.avoid_human(confidence)

    def play_buzzer_pattern(self, pattern: str = "obstacle"):
        """Joue un motif sonore sur le buzzer."""
        if not GPIO_AVAILABLE or not hasattr(self, "buzzer_pin"):
            return
        if hasattr(self, "buzzer_enabled") and not self.buzzer_enabled.get():
            return

        def beep(duration_ms):
            try:
                GPIO.output(self.buzzer_pin, GPIO.HIGH)
                time.sleep(duration_ms / 1000.0)
                GPIO.output(self.buzzer_pin, GPIO.LOW)
            except Exception:
                pass

        if pattern == "human":
            threading.Thread(target=beep, args=(400,), daemon=True).start()
        else:
            def double_beep():
                beep(150)
                time.sleep(0.1)
                beep(150)
            threading.Thread(target=double_beep, daemon=True).start()

    def send_drive_command(self, action, **kwargs):
        if not self.motor_bridge:
            return False
        payload = {"action": action, **kwargs}
        success = self.motor_bridge.send_command(payload)
        if not success:
            self.show_toast("‚ùå Commande moteur √©chou√©e")
        return success

    def stop_robot(self, reason="safety"):
        """Arr√™t imm√©diat."""
        if self.send_drive_command("stop", reason=reason):
            self.status_var.set(f"‚õî Arr√™t d'urgence ({reason})")

    def resume_navigation(self):
        if self.send_drive_command("resume"):
            self.status_var.set("‚ñ∂Ô∏è Navigation nominale")

    def avoid_human(self, confidence):
        """G√®re l'√©vitement d'un √™tre humain."""
        self.stop_robot(reason="human_detected")
        self.status_var.set(f"üö® Humain d√©tect√© - Arr√™t et calcul navigation...")
        
        stop_duration_ms = int(self.human_avoidance_stop_duration * 1000)
        
        def calculate_and_avoid():
            turn_direction = self.last_turn_direction
            self.last_turn_direction = "right" if turn_direction == "left" else "left"
            
            # Log
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            try:
                with open(self.log_file, "a", newline="") as f:
                    writer = csv.writer(f)
                    writer.writerow([timestamp, "NAVIGATION", "√âvitement Humain", "CALCUL", f"Direction: {turn_direction}"])
            except Exception as e:
                print(f"‚ùå Erreur log navigation: {e}")
            
            self.status_var.set(f"üîÑ Calcul termin√© ‚Üí Virage {turn_direction} pour √©viter l'humain")
            
            if self.send_drive_command(
                "avoid",
                label="human",
                turn=turn_direction,
                duration=self.human_avoidance_turn_duration,
            ):
                self.show_toast(f"üîÑ Changement de direction: {turn_direction}", duration=2000)
                
                def resume_after_turn():
                    self.resume_navigation()
                    self.is_avoiding_human = False
                    self.status_var.set("‚úÖ Navigation reprise - Trajectoire mise √† jour")
                
                self.root.after(self.human_avoidance_turn_duration + 500, resume_after_turn)
            else:
                self.root.after(2000, lambda: setattr(self, 'is_avoiding_human', False))
        
        self.root.after(stop_duration_ms, calculate_and_avoid)

    def avoid_obstacle(self, label, duration_ms=800):
        """Contourne un obstacle."""
        turn_direction = self.last_turn_direction
        self.last_turn_direction = "right" if turn_direction == "left" else "left"
        if self.send_drive_command(
            "avoid",
            label=label,
            turn=turn_direction,
            duration=duration_ms,
        ):
            self.status_var.set(f"üîÑ √âvitement {label} ‚Üí {turn_direction}")
            self.root.after(duration_ms + 500, self.resume_navigation)

    def handle_obstacle_detection(self, label, confidence):
        """G√®re la d√©tection d'obstacle."""
        if not self.smart_obstacle_mode.get():
            return

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        detail = f"Obstacle {label} (confiance: {confidence:.2f})"

        try:
            with open(self.log_file, "a", newline="") as f:
                writer = csv.writer(f)
                writer.writerow([timestamp, "NAVIGATION", "Obstacle", "INFO", detail])
        except Exception as e:
            print(f"‚ùå Erreur log obstacle: {e}")

        self.show_toast(f"‚ö†Ô∏è Obstacle d√©tect√©: {label}", duration=2500)
        self.status_var.set(f"‚ö†Ô∏è Obstacle d√©tect√© ‚Üí recalcul trajectoire ({label})")
        self.play_buzzer_pattern("obstacle")
        self.avoid_obstacle(label)

    def toggle_surveillance_mode(self):
        """Active/d√©sactive le mode surveillance."""
        if self.surveillance_mode.get():
            if not self.yolo_enabled.get():
                self.show_toast("‚ö†Ô∏è Activez 'YOLO Person' d'abord pour la surveillance", duration=3000)
                self.surveillance_mode.set(False)
                return
            
            self.show_toast("üîç Mode Surveillance ACTIV√â", duration=3000)
            self.detection_count = 0
            self.current_detections = 0
            self.surveillance_status_var.set("üîç SURVEILLANCE ACTIVE")
            self.surveillance_status_label.config(text="Surveillance: ACTIVE", foreground="green")
            self.current_detection_summary = {"human": 0, "obstacle": 0}
            self.detection_count_label.config(text="D√©tections actuelles: H=0 | O=0 | Alertes totales: 0")
            
            if not self.yolo_enabled.get():
                self.yolo_enabled.set(True)
                self.show_toast("‚úÖ YOLO Person activ√© automatiquement")
        else:
            self.show_toast("üîç Mode Surveillance D√âSACTIV√â", duration=2000)
            self.surveillance_status_var.set("")
            self.surveillance_status_label.config(text="Surveillance: INACTIVE", foreground="red")

    def setup_gui(self):
        # Menu bar
        self.menubar = tk.Menu(self.root, bg="#34495e", fg="#ecf0f1")
        self.root.config(menu=self.menubar)
        
        file_menu = tk.Menu(self.menubar, tearoff=0, bg="#2c3e50", fg="#ecf0f1")
        file_menu.add_command(label="üìÅ Charger Image", command=self.load_image)
        file_menu.add_command(label="üíæ Sauvegarder Image", command=self.save_image)
        file_menu.add_separator()
        file_menu.add_command(label="üö™ Quitter", command=self.on_closing)
        self.menubar.add_cascade(label="Fichier", menu=file_menu)
        
        # Main layout
        self.main_frame = ttk.Frame(self.root, padding=10)
        self.main_frame.pack(fill=tk.BOTH, expand=True)
        
        # Status bar
        self.status_frame = ttk.Frame(self.main_frame, relief=tk.SUNKEN, borderwidth=1)
        self.status_frame.pack(side=tk.BOTTOM, fill=tk.X)
        self.status_var = tk.StringVar(value="ü§ñ Robot de Surveillance - Pr√™t")
        ttk.Label(self.status_frame, textvariable=self.status_var).pack(side=tk.LEFT, padx=5)
        self.time_var = tk.StringVar()
        ttk.Label(self.status_frame, textvariable=self.time_var).pack(side=tk.RIGHT, padx=5)
        
        # Mode selector
        self.mode_selector = ttk.Combobox(
            self.status_frame,
            textvariable=self.mode,
            values=["Mode R√©glage", "Run Mode"],
            state="readonly",
            width=15
        )
        self.mode_selector.pack(side=tk.RIGHT, padx=5)
        
        # Detection toggles
        ttk.Checkbutton(self.status_frame, text="üë§ YOLO Person", variable=self.yolo_enabled).pack(side=tk.RIGHT, padx=5)
        ttk.Checkbutton(self.status_frame, text="üòÄ Visage (Haar)", variable=self.face_enabled).pack(side=tk.RIGHT, padx=5)
        ttk.Checkbutton(self.status_frame, text="üì¶ Tous Objets", variable=self.detect_all_objects).pack(side=tk.RIGHT, padx=5)
        ttk.Checkbutton(self.status_frame, text="üß† √âvitement Intelligent", variable=self.smart_obstacle_mode).pack(side=tk.RIGHT, padx=5)
        ttk.Checkbutton(self.status_frame, text="üîä Buzzer", variable=self.buzzer_enabled).pack(side=tk.RIGHT, padx=5)
        
        # Surveillance mode toggle
        surveillance_cb = ttk.Checkbutton(
            self.status_frame,
            text="üîç Surveillance",
            variable=self.surveillance_mode,
            command=self.toggle_surveillance_mode
        )
        surveillance_cb.pack(side=tk.RIGHT, padx=5)
        
        # Surveillance status indicator
        self.surveillance_status_var = tk.StringVar(value="")
        ttk.Label(
            self.status_frame,
            textvariable=self.surveillance_status_var,
            foreground="#e74c3c",
            font=("Segoe UI", 9, "bold")
        ).pack(side=tk.RIGHT, padx=5)
        
        self.update_time()
        
        # Paned window
        self.paned_window = ttk.PanedWindow(self.main_frame, orient=tk.HORIZONTAL)
        self.paned_window.pack(fill=tk.BOTH, expand=True)
        
        # Left panel: Video
        self.left_panel = ttk.Frame(self.paned_window)
        self.paned_window.add(self.left_panel, weight=1)
        
        self.canvas = tk.Canvas(
            self.left_panel,
            width=640,
            height=480